# Scrape Toronto events and update events.json + last_update.json
# Runs on schedule and manual trigger; commits and pushes so deploy-pages can publish.
name: Scrape events

on:
  workflow_dispatch:
  schedule:
    - cron: '0 12 * * *'   # daily 12:00 UTC

permissions:
  contents: write   # read + push for events.json and last_update.json

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      # Exception: STOCKSUNIFY is a git submodule (see https://github.com/eltonaguiar/stocksunify). Remove its broken .gitmodules entry so checkout post step doesn't fail with exit 128.
      - name: Fix broken submodule entry
        run: |
          if [ -f .gitmodules ]; then
            git config -f .gitmodules --remove-section submodule.STOCKSUNIFY 2>/dev/null || true
          fi

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: pip install requests beautifulsoup4 lxml

      - name: Verify scraper imports
        run: python -c "import sys; sys.path.insert(0, 'tools'); from scrapers.unified_scraper import UnifiedTorontoScraper; print('imports OK')"

      - name: Ensure next/ exists
        run: mkdir -p next

      - name: Run scraper and sync to database
        env:
          EVENTS_UPDATE_SOURCE: github_actions
        run: python tools/scrape_and_sync_events.py --sync

      - name: Setup Node for cleanup
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Cleanup past events from scraped data
        run: node tools/cleanup_past_events.js

      - name: Verify calendar source (sofiaadelgiudice) in events.json
        run: |
          count=$(python -c "
          import json
          with open('events.json') as f:
              data = json.load(f)
          events = data if isinstance(data, list) else data.get('events', [])
          n = sum(1 for e in events if (e.get('source') or '').strip() == 'sofiaadelgiudice')
          print(n)
          ")
          echo "sofiaadelgiudice events in events.json: $count"
          if [ "$count" -lt 1 ]; then
            echo "::error::events.json has no sofiaadelgiudice events; scraper or merge may have failed."
            exit 1
          fi

      - name: Commit and push if changed
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git add events.json last_update.json
          [ -f next/events.json ] && git add next/events.json
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            git commit -m "chore: update events from scraper (GitHub Actions)"
            git push "https://x-access-token:${GH_TOKEN}@github.com/${{ github.repository }}.git" HEAD:main
          fi

      # Trigger the server to re-sync its database from its own events.json
      # This is a fallback in case the --sync POST was blocked by ModSecurity (412)
      - name: Trigger database sync via GET
        run: |
          echo "Triggering server-side database sync..."
          RESPONSE=$(curl -s -w "\n%{http_code}" \
            -A "Mozilla/5.0 (compatible; FindTorontoEvents-Sync/1.0)" \
            "https://findtorontoevents.ca/fc/api/events_sync.php" \
            --max-time 120)
          HTTP_CODE=$(echo "$RESPONSE" | tail -n1)
          BODY=$(echo "$RESPONSE" | sed '$d')
          echo "HTTP $HTTP_CODE"
          echo "$BODY" | python -m json.tool 2>/dev/null || echo "$BODY"
          if [ "$HTTP_CODE" -ge 200 ] && [ "$HTTP_CODE" -lt 300 ]; then
            echo "Database sync triggered successfully"
          else
            echo "::warning::Database sync returned HTTP $HTTP_CODE (non-fatal)"
          fi

      - name: Trigger server-side past events cleanup
        run: |
          echo "Cleaning up past events on server..."
          RESPONSE=$(curl -s -w "\n%{http_code}" \
            -A "Mozilla/5.0 (compatible; FindTorontoEvents-Cleanup/1.0)" \
            "https://findtorontoevents.ca/api/events/cleanup_events.php" \
            --max-time 60)
          HTTP_CODE=$(echo "$RESPONSE" | tail -n1)
          BODY=$(echo "$RESPONSE" | sed '$d')
          echo "HTTP $HTTP_CODE"
          echo "$BODY" | python -m json.tool 2>/dev/null || echo "$BODY"

      # Reset workspace so checkout action's post step doesn't fail with git 128
      - name: Restore workspace for checkout post
        if: always()
        run: |
          git checkout --detach ${{ github.sha }}
          git reset --hard ${{ github.sha }}
